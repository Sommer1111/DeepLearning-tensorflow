{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、对于神经网络层结构、模型结构来讲，一般的操作可以直接调用函数，但有些时候需要有一些特定的操作，这是需要自定义层\n",
    "---\n",
    "## 二、自定义层用到的思想就是python里面的继承，继承母类得到的自定义类，带有母类的属性，又有了自由发挥的空间\n",
    "\n",
    "## 三、keras有两个关于神经网络层的大类，分别为keras.layers.Layer 和 keras.Model\n",
    "\n",
    "## 四、两者实现的功能非常的类似，只是layer更小范围，我们可以继承它的构建神经网络层。而相对的Model更适合构建整体的框架结构\n",
    "\n",
    "## 五、Model还带有compile、fit、predict这些功能，而layer没有\n",
    "\n",
    "## 六、现在比较熟悉的Sequential就是model的子类，用以构建网络结构非常的方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义层需要实现两个功能\n",
    "## 1、__init__初始化\n",
    "## 2、call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现layer的继承，自定义\n",
    "Class MyDense(keras.layers.Layer):\n",
    "    def __init__(self,inp_dim,outp_dim):\n",
    "        super(MyDense,self).__init__()#调用母类的初始化，实现初始化的功能\n",
    "        \n",
    "        self.kernel = self.add_variable('w',[inp_dim,outp_dim])\n",
    "        #调用add_variable方法使生成的变量加到它原来的变量群中，带有共同的属性\n",
    "        #不分主次内外，一视同仁，利于集成混合使用\n",
    "        self.bias = self.add_variable('b',[oup_dim])\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        #传值的规则，即用来事项正向传播反向传播\n",
    "        out = input @ self.kernel + self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现Model的继承，自定义\n",
    "Class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.fc1 = MyDense(28*28,256)\n",
    "        self.fc2 = MyDense(256,128)\n",
    "        self.fc3 = MyDebse(128,64)\n",
    "        self.fc4 = MyDense(64,32)\n",
    "        self.fc5 = MyDebse(32,10)\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        #每一层我们都用了一个变量x来代表，这就表示我们可能单独对某一个层进行操作\n",
    "        # 这是Sequential不具有的开放性\n",
    "        x = self.fc1(inputs)\n",
    "        x= tf,nn,relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = tf,nn.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x= tf.nn.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
